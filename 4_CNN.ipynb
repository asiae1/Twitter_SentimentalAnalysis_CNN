{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yZT-AnYWVOP_","colab_type":"code","colab":{}},"source":["from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFI_-m0VVOQC","colab_type":"code","colab":{}},"source":["#라벨링한 csv 파일 불러오기\n","data = pd.read_csv(\"KoreanAir_label.csv\").dropna(axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGZSBuuYZJQk","colab_type":"code","outputId":"bb9cf47f-2f73-46b9-eb23-8901f24c17f8","executionInfo":{"status":"ok","timestamp":1559534441980,"user_tz":-540,"elapsed":2368,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.shape #데이터의 개수 확인"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(118473, 5)"]},"metadata":{"tags":[]},"execution_count":159}]},{"cell_type":"code","metadata":{"id":"RJCj8j3eoKhe","colab_type":"code","colab":{}},"source":["data = data.sample(frac =1) # 1개 단위로 섞기"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"msmRhYLhVOQE","colab_type":"code","colab":{}},"source":["# 60 : 40 의 비율로 트레인셋, 테스트셋 나눔\n","Train = data.loc[:71000]\n","Test = data.loc[71000:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3E9AVM1cVOQG","colab_type":"code","colab":{}},"source":["X_train = Train['preprocessing'].str.split(',').values.tolist()\n","y_train_label = Train['Label'].values.tolist()\n","\n","X_test = Test['preprocessing'].str.split(',').values.tolist()\n","y_test_label = Test['Label'].values.tolist()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xM6mTCQyVOQZ","colab_type":"text"},"source":["# CNN"]},{"cell_type":"code","metadata":{"id":"rEikXlrkVOQa","colab_type":"code","colab":{}},"source":["from collections import defaultdict\n","import torch.nn as nn\n","import torch\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwju8gn3VOQc","colab_type":"code","colab":{}},"source":["# 단어에 대한 idx 부여\n","def convert_token_to_idx(token_ls):\n","    for tokens in token_ls:\n","        yield [token2idx[token] for token in tokens]\n","    return"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GL4_xKuqVOQ1","colab_type":"text"},"source":["#Add Padding"]},{"cell_type":"code","metadata":{"id":"Um1XY368VOQ2","colab_type":"code","colab":{}},"source":["token2idx = defaultdict(lambda : len(token2idx)) # token과 index를 매칭시켜주는 딕셔너리\n","pad = token2idx['<PAD>']  # pytorch Variable로 변환하기 위해, 문장의 길이를 맞춰주기 위한 padding \n","\n","x_train = list(convert_token_to_idx(X_train))\n","x_test = list(convert_token_to_idx(X_test))\n","\n","idx2token = {val : key for key,val in token2idx.items()}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HP6gFB1MVOQ3","colab_type":"code","colab":{}},"source":["#Sequence Length를 맞추기 위한 padding\n","def add_padding(token_ls, max_len):\n","    for i, tokens in enumerate(token_ls):\n","        n_token = len(tokens)\n","        \n","        # 길이가 짧으면 padding을 추가\n","        if n_token < max_len:\n","            token_ls[i] += [pad] * (max_len - n_token) # 부족한 만큼 padding을 추가함\n","        \n","        # 길이가 길면, max_len에서 짜름\n","        elif n_token > max_len:\n","            token_ls[i] = tokens[:max_len]\n","    return token_ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LVVMKtGxVOQ7","colab_type":"code","colab":{}},"source":["max_len = 200\n","x_train = add_padding(x_train, max_len)\n","x_test = add_padding(x_test, max_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGdlOMdKVOQ9","colab_type":"code","outputId":"0a15f0ab-8580-4f41-8be0-490f894e7a7c","executionInfo":{"status":"ok","timestamp":1559534443029,"user_tz":-540,"elapsed":3315,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["' '.join([idx2token[x] for x in x_train[0]])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'규현 대한항공 종신 아이디 규용 규디 소울 <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"]},"metadata":{"tags":[]},"execution_count":169}]},{"cell_type":"markdown","metadata":{"id":"QQ1BtemtmtcL","colab_type":"text"},"source":["#Pytorch 모델 학습을 위해 Data의 type을 Variable 로 변환"]},{"cell_type":"code","metadata":{"id":"VK-EPEHKVOQ_","colab_type":"code","colab":{}},"source":["# torch Variable로 변환\n","def convert_to_long_variable(w2i_ls):\n","    return Variable(torch.LongTensor(w2i_ls))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxMlSCQoVORA","colab_type":"code","colab":{}},"source":["x_train = convert_to_long_variable(x_train)\n","x_test = convert_to_long_variable(x_test)\n","\n","y_train = convert_to_long_variable(y_train_label)\n","y_test = convert_to_long_variable(y_test_label)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9C4hXRVom3pl","colab_type":"text"},"source":["#CNN with Pytorch"]},{"cell_type":"code","metadata":{"id":"NOFVAeSPVORE","colab_type":"code","colab":{}},"source":["class CNN_text(nn.Module):\n","    \n","    def __init__(self, n_words, embed_size, pad_index, hid_size, drop_rate, kernel_size_ls, num_filter, n_class):\n","        super(CNN_text, self).__init__()\n","        \n","        self.pad_index = pad_index              # 단어 embedding 과정에서 제외시킬 padding token\n","        self.embed_size = embed_size            # 임베딩 차원의 크기\n","        self.hid_size = hid_size                # 히든 레이어 갯수\n","        self.drop_rate = drop_rate              # 드롭아웃 비율\n","        self.num_filter = num_filter            # 필터의 갯수 \n","        self.kernel_size_ls = kernel_size_ls    # 각기 다른 필터 사이즈가 담긴 리스트\n","        self.num_kernel = len(kernel_size_ls)   # 필터 사이즈의 종류 수\n","        self.n_class = n_class                  # 카테고리 갯수\n","        \n","        self.embed = nn.Embedding(\n","            num_embeddings=n_words, \n","            embedding_dim=embed_size,\n","            padding_idx=self.pad_index\n","        )\n","        \n","        \n","        # kernel size는 (n-gram, embed_size)이다.\n","        # 커널의 열(column)의 크기는 embed_size와 일치하므로, 단어 임베딩 벡터를 모두 커버한다.\n","        # 따라서, n의 row 크기를 갖는 커널은 한번에 n개의 단어를 커버하는 n-gram 커널이라고 볼 수 있다.\n","        self.convs = nn.ModuleList([nn.Conv2d(1, num_filter, (kernel_size, embed_size)) for kernel_size in kernel_size_ls])\n","        \n","        self.lin = nn.Sequential(\n","            nn.Linear(self.num_kernel*num_filter, hid_size), nn.ReLU(), nn.Dropout(drop_rate),\n","            nn.Linear(hid_size, n_class),\n","        )\n","        \n","    def forward(self, x):\n","        embed = self.embed(x) # batch_size x max_length x embed_size\n","        embed.unsqueeze_(1)       # batch_size, 1, max_length, embed_size : convolution을 위해 4D로 차원을 조절\n","        \n","        # convolution\n","        conved = [conv(embed).squeeze(3) for conv in self.convs] # [batch_size, num_filter, max_length -kernel_size +1]\n","        \n","        # max_pooling\n","        pooled = [F.max_pool1d(conv, (conv.size(2))).squeeze(2) for conv in conved] # [batch_size, num_kernel, num_filter]\n","            \n","        # dropout\n","        dropouted = [F.dropout(pool, self.drop_rate) for pool in pooled]\n","        \n","        # concatenate\n","        concated = torch.cat(dropouted, dim = 1) # [batch_size, num_kernel * num_filter]\n","        logit = self.lin(concated)\n","        \n","        return logit"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMA3QrsuVORG","colab_type":"code","colab":{}},"source":["params = {\n","    'n_words' : len(token2idx),        # 고유한 단어 토큰의 갯수\n","    'embed_size' : 50,                # 임베딩 차원의 크기\n","    'pad_index' : token2idx['<PAD>'],  # 패딩 토큰\n","    'hid_size' : 50,                  # 히든 레이어 갯수\n","    'drop_rate' : 0.5,                 # 드롭아웃 비율          (원문에서는 0.5를 사용)\n","    'kernel_size_ls' : [3,4,5],      # 커널 사이즈 리스트        (원문에서는 3,4,5를 사용)\n","    'num_filter' : 50,                 # 각 사이즈 별 커널 갯수 (원문에서는 100을 사용)\n","    'n_class' : 3,                  # 카테고리 갯수\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nwxxy4q9VORI","colab_type":"code","colab":{}},"source":["model = CNN_text(**params)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOhBy-zpVORK","colab_type":"code","outputId":"f40be6dd-8916-45fb-9d38-4abbebf01b01","executionInfo":{"status":"ok","timestamp":1559534443367,"user_tz":-540,"elapsed":3575,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"source":["model"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN_text(\n","  (embed): Embedding(2720, 50, padding_idx=0)\n","  (convs): ModuleList(\n","    (0): Conv2d(1, 50, kernel_size=(3, 50), stride=(1, 1))\n","    (1): Conv2d(1, 50, kernel_size=(4, 50), stride=(1, 1))\n","    (2): Conv2d(1, 50, kernel_size=(5, 50), stride=(1, 1))\n","  )\n","  (lin): Sequential(\n","    (0): Linear(in_features=150, out_features=50, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=50, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":176}]},{"cell_type":"code","metadata":{"id":"9320eYjhVORL","colab_type":"code","outputId":"4ad0fd78-0112-484d-ea64-4cee224000f7","executionInfo":{"status":"ok","timestamp":1559534443368,"user_tz":-540,"elapsed":3569,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(list(model.parameters()))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{"tags":[]},"execution_count":177}]},{"cell_type":"code","metadata":{"id":"A2b5JENkVORN","colab_type":"code","outputId":"b85eb777-9a03-4676-aa2c-d8e0c0eca351","executionInfo":{"status":"ok","timestamp":1559534552632,"user_tz":-540,"elapsed":112825,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["import numpy as np\n","epochs = 1\n","lr = 0.01\n","batch_size = 100\n","\n","train_idx = np.arange(x_train.size(0))\n","test_idx = np.arange(x_test.size(0))\n","optimizer = torch.optim.Adam(model.parameters(),lr) # 원문에서는 Adadelta 알고리즘을 사용\n","criterion = nn.CrossEntropyLoss(reduction='sum')\n","\n","loss_ls = []\n","\n","for epoch in range(epochs):\n","    model.train()\n","    \n","    # input 데이터 순서 섞기\n","    random.shuffle(train_idx)\n","    x_train = x_train[train_idx]\n","    y_train = y_train[train_idx]\n","    train_loss = 0\n","\n","    for start_idx, end_idx in zip(range(0, x_train.size(0), batch_size),\n","                                  range(batch_size, x_train.size(0)+1, batch_size)):\n","        \n","        x_batch = x_train[start_idx : end_idx]\n","        y_batch = y_train[start_idx : end_idx].long()\n","        \n","        scores = model(x_batch)\n","        predict = F.softmax(scores, dim=1).argmax(dim = 1)\n","        \n","        acc = (predict == y_batch).sum().item() / batch_size\n","        \n","        loss = criterion(scores, y_batch)\n","        train_loss += loss.item()\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    print('Train epoch : %s,  loss : %s,  accuracy :%.3f'%(epoch+1, train_loss / batch_size, acc))\n","    print('=================================================================================================')\n","    \n","    loss_ls.append(train_loss)\n","    \n","    if (epoch+1) % 1 == 0:\n","        model.eval()\n","        scores = model(x_test)\n","        predict = F.softmax(scores, dim=1).argmax(dim = 1)\n","        \n","        acc = (predict == y_test.long()).sum().item() / y_test.size(0)\n","        loss = criterion(scores, y_test.long())\n","        \n","        print('*************************************************************************************************')\n","        print('*************************************************************************************************')\n","        print('Test Epoch : %s, Test Loss : %.03f , Test Accuracy : %.03f'%(epoch+1, loss.item()/y_test.size(0), acc))\n","        print('*************************************************************************************************')\n","        print('*************************************************************************************************')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train epoch : 1,  loss : 675.750672531128,  accuracy :0.590\n","=================================================================================================\n","*************************************************************************************************\n","*************************************************************************************************\n","Test Epoch : 1, Test Loss : 0.696 , Test Accuracy : 0.665\n","*************************************************************************************************\n","*************************************************************************************************\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ThDNax7hqbYa","colab_type":"text"},"source":["# 예측값"]},{"cell_type":"code","metadata":{"id":"awmDwCWuV-wX","colab_type":"code","colab":{}},"source":["x_predict_data = X_train[50]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9GvTLkHV-ti","colab_type":"code","outputId":"84237547-abd1-4563-e7ae-d8bf94c35abb","executionInfo":{"status":"ok","timestamp":1559535379852,"user_tz":-540,"elapsed":738,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(\"랜덤 날짜:\", data['Date'][8500])\n","print(\"원래 라벨 값 확인하기:\", data['Label'][8500])\n","print(\"단어 보기:\", data['preprocessing'][8500])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2015-04-17'"]},"metadata":{"tags":[]},"execution_count":246}]},{"cell_type":"code","metadata":{"id":"F-na9U7rV-hu","colab_type":"code","colab":{}},"source":["# 토큰화 된 1개의 문서를 이중리스트로 만들기\n","x_predict_data_2 = []\n","x_predict_data_2.append(x_predict_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_DYahEfKV-Wq","colab_type":"code","colab":{}},"source":["x_test = list(convert_token_to_idx(x_predict_data_2))\n","x_test = add_padding(x_test, max_len)\n","x_test = convert_to_long_variable(x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0FDso2fWwsp","colab_type":"code","colab":{}},"source":["scores = model(x_test)\n","predict = F.softmax(scores, dim=1).argmax(dim = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sS5jyadRW4Nb","colab_type":"code","outputId":"16b9d568-c6bb-47cb-ef70-449aceed0c44","executionInfo":{"status":"ok","timestamp":1559535393385,"user_tz":-540,"elapsed":742,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["predict # 라벨 예측값"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0])"]},"metadata":{"tags":[]},"execution_count":256}]},{"cell_type":"code","metadata":{"id":"GjF3TpPgW5kd","colab_type":"code","outputId":"d542777e-dfcb-4bcb-ce6a-b52e057e46bd","executionInfo":{"status":"ok","timestamp":1559535394326,"user_tz":-540,"elapsed":622,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["predict_ls = predict.numpy()\n","predict_ls[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":257}]},{"cell_type":"code","metadata":{"id":"xDtFtZMvW9FF","colab_type":"code","outputId":"c0f8bb6c-df78-4f02-8ac1-c8eb0c64abca","executionInfo":{"status":"ok","timestamp":1559535395430,"user_tz":-540,"elapsed":678,"user":{"displayName":"Harim Kim","photoUrl":"https://lh3.googleusercontent.com/-cguPt4R8mws/AAAAAAAAAAI/AAAAAAAAAB0/W1-SFEKQZGE/s64/photo.jpg","userId":"06517090890766429917"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["F.softmax(scores, dim=1)\n","# 각각 0, 1, 2 값이 나올 확률"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8676, 0.0010, 0.1314]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":258}]}]}